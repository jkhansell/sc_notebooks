{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Conectar cuaderno a la GPU."
      ],
      "metadata": {
        "id": "Ww8IQ0LJbs--"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uINg123MsGe8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "import time\n",
        "import numba\n",
        "from numba import cuda\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy\n",
        "print(\"NumPy:\")\n",
        "arr_np = np.random.rand(10_000_000)\n",
        "np_time = %timeit -o np.square(arr_np)\n",
        "\n",
        "# JAX\n",
        "print(\"\\nJAX:\")\n",
        "arr_jax = jnp.array(arr_np)\n",
        "square_fn = jit(jnp.square)\n",
        "jax_time = %timeit -o square_fn(arr_jax).block_until_ready()\n",
        "\n",
        "# Numba\n",
        "print(\"\\nNumba:\")\n",
        "\n",
        "@numba_jit\n",
        "def square_numba(arr):\n",
        "    return arr * arr\n",
        "numba_time = %timeit -o square_numba(arr_np)\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nNumPy Square Time:\", np_time.best)\n",
        "print(\"JAX Square Time:\", jax_time.best)\n",
        "print(\"Numba Square Time:\", numba_time.best)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K49jZnI2s5kP",
        "outputId": "019170a8-6c9f-48ae-ed20-bf93044085db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy:\n",
            "21 ms ± 173 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "\n",
            "JAX:\n",
            "512 µs ± 3.59 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "\n",
            "Numba:\n",
            "57.1 ms ± 1.43 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
            "\n",
            "NumPy Square Time: 0.020709080799997538\n",
            "JAX Square Time: 0.0005079865359998621\n",
            "Numba Square Time: 0.055021133000082045\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NumPy\n",
        "print(\"NumPy:\")\n",
        "mat_np = np.random.rand(1000, 1000)\n",
        "mat_np_result = np.matmul(mat_np, mat_np)\n",
        "np_time = %timeit -o np.matmul(mat_np, mat_np)\n",
        "\n",
        "# JAX\n",
        "print(\"\\nJAX:\")\n",
        "mat_jax = jnp.array(mat_np)\n",
        "mat_jax_result = jnp.matmul(mat_jax, mat_jax)\n",
        "jax_time = %timeit -o jnp.matmul(mat_jax, mat_jax).block_until_ready()\n",
        "\n",
        "# Numba\n",
        "@cuda.jit\n",
        "def matmul(a, b, out):\n",
        "    x, y = cuda.grid(2)\n",
        "    if x < out.shape[0] and y < out.shape[1]:\n",
        "        out[x,y] = a[x,y]*b[y,x]\n",
        "\n",
        "TPB = (16,16)\n",
        "BPG = (math.ceil(mat_np.shape[0]/TPB[0]),\n",
        "       math.ceil(mat_np.shape[0]/TPB[0]))\n",
        "\n",
        "out = cuda.device_array((1000,1000))\n",
        "print(\"\\nNumba:\")\n",
        "\n",
        "numba_time = %timeit -o matmul[BPG, TPB](mat_np, mat_np, out)\n",
        "\n",
        "print(\"\\nNumPy Matrix Multiplication Time:\", np_time.best)\n",
        "print(\"JAX Matrix Multiplication Time:\", jax_time.best)\n",
        "print(\"Numba Matrix Multiplication Time:\", numba_time.best)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bI2nDN8GtJ82",
        "outputId": "69143f99-80e1-4c38-d8e0-891c4bb4b629"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy:\n",
            "57.6 ms ± 5.29 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
            "\n",
            "JAX:\n",
            "600 µs ± 7.33 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "\n",
            "Numba:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numba/cuda/cudadrv/devicearray.py:885: NumbaPerformanceWarning: Host array used in CUDA kernel will incur copy overhead to/from device.\n",
            "  warn(NumbaPerformanceWarning(msg))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.19 ms ± 350 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "\n",
            "NumPy Matrix Multiplication Time: 0.053225178299999246\n",
            "JAX Matrix Multiplication Time: 0.0005902321309999934\n",
            "Numba Matrix Multiplication Time: 0.008006213300000127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX = 255.0\n",
        "\n",
        "@jax.jit\n",
        "def stencil_iter(grid):\n",
        "    grid = grid.at[1:-1, 1:-1, 1:-1].set((grid[1:-1, 1:-1, 1:-1] + grid[0:-2, 1:-1, 1:-1] +\n",
        "                                            grid[2:, 1:-1, 1:-1] + grid[1:-1, 0:-2, 1:-1] +\n",
        "                                            grid[1:-1, 2:, 1:-1] + grid[1:-1, 1:-1, 0:-2] +\n",
        "                                            grid[1:-1, 1:-1, 2:]) / 7.0)\n",
        "    return grid\n",
        "\n",
        "def stencil(grid, max_iter):\n",
        "    # Creating initial matrix\n",
        "    # Setting first column and first row to maximum value\n",
        "    grid = grid.at[:,0,:].add(MAX)\n",
        "    grid = grid.at[:,-1,:].add(MAX)\n",
        "\n",
        "    #jax.ops.index_update(grid, jax.ops.index[:, 0, :], grid[:, 0, :] + MAX)\n",
        "    #grid = jax.ops.index_update(grid, jax.ops.index[:, -1, :], grid[:, -1, :] + MAX)\n",
        "\n",
        "    # Applying the stencil computation to the whole multidimensional array\n",
        "    for _ in range(max_iter):\n",
        "        grid = stencil_iter(grid)\n",
        "\n",
        "    # jax.ops.index_update(grid, jax.ops.index[1:-1, 1:-1, 1:-1],\n",
        "    return grid\n"
      ],
      "metadata": {
        "id": "hO7DKZ1TZBUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    print(jax.devices()[0])\n",
        "    size = 250\n",
        "    max_iter = 1000\n",
        "    arr = jnp.zeros(shape=(size, size, size))\n",
        "    gpu_arr = jax.device_put(arr)\n",
        "    print(gpu_arr.device_buffer.device())\n",
        "    a = time.perf_counter()\n",
        "    stencil(gpu_arr, max_iter)\n",
        "    b = time.perf_counter()\n",
        "    print(b-a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF-_O_HlZNoC",
        "outputId": "bf342873-2e72-4317-8850-4d6469bb4811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gpu:0\n",
            "gpu:0\n",
            "6.026596316999985\n"
          ]
        }
      ]
    }
  ]
}